{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main BAM Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y1bLONN3_A-",
        "outputId": "e6084ef9-8215-41b7-e6f8-560bff5f3783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current best image found: 1 with similarity of 1.4445382157118654\n",
            "Current best image found: 45 with similarity of 1.4430963857118653\n",
            "Current best image found: 126 with similarity of 1.4423692057118656\n",
            "Current best image found: 143 with similarity of 1.4044606101506856\n",
            "Current best image found: 216 with similarity of 1.342028685150685\n",
            "Current best image found: 239 with similarity of 1.3033149728109406\n",
            "Current best image found: 300 with similarity of 1.293730185662923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "### Main cell - this needs to be run last generally, but has been put here for simplicity\n",
        "# The function takes 4 inputs: The directory of the image to find clothes based on, the image-emotion CNN, the image-mediatype CNN, and the feature-style CNN\n",
        "# If the CNNs are not provided, they default to the locations shown\n",
        "predict_image_style(  imgdir = \"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/BAM/images-annotated/images-annotated/0000/1220000.jpg\",\n",
        "                      emote_predictor = Predictor(\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/BAM/models/2022-07-13/prototype-emotion-1\"),\n",
        "                      media_predictor = Predictor(\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/BAM/models/2022-07-13/prototype-media-1\"),\n",
        "                      style_predictor = Predictor(\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/HipsterWars/models/widths = 1024,2048,128;activations = relu,relu,relu;lrate = 0.0001;epochs = 50\"),\n",
        "                      prediction_weightings = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlaI5WZY4FaU",
        "outputId": "241b73d4-b40a-4da7-f113-bdc0375d87e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Functions needed for the predict_image_style function to work\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "class Predictor:\n",
        "  def __init__(self,model_dir):\n",
        "    self.model_dir = model_dir\n",
        "    self.model = tf.keras.models.load_model(model_dir)\n",
        "    p_start = model_dir.rfind(\"/\")+1\n",
        "    self.model_name = model_dir[p_start:]\n",
        "    return\n",
        "\n",
        "# Take an input image directory and find the most similar clothing results using both predicted and true outputs\n",
        "def predict_image_style(imgdir,\n",
        "                        emote_predictor = Predictor(\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/BAM/models/2022-07-13/prototype-emotion-1\"),\n",
        "                        media_predictor = Predictor(\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/BAM/models/2022-07-13/prototype-media-1\"),\n",
        "                        style_predictor = Predictor(\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/HipsterWars/models/widths = 1024,2048,128;activations = relu,relu,relu;lrate = 0.0001;epochs = 50\"),\n",
        "                        prediction_weightings = 0.5):\n",
        "  # Predict the style for this image\n",
        "  feature_tens = predict_features([imgdir],emote_predictor,media_predictor)\n",
        "  style_tens = style_predictor.model.predict(feature_tens)\n",
        "  ## Get the actual and predicted styles of known clothes\n",
        "  styles_actual = get_hipsterdata()\n",
        "  styles_predicted_dir = \"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/HipsterWars/clothing_predictions/\" + \\\n",
        "                        f\"emote_predictor,{emote_predictor.model_name};media_predictor,{media_predictor.model_name};style_predictor,{style_predictor.model_name}.csv\"\n",
        "  styles_predicted = pd.read_csv(styles_predicted_dir)\n",
        "  # Create a combined dataframe\n",
        "  actual_outs,actual_ids,pred_outs,pred_ids = list(styles_actual[\"style\"]),list(styles_actual[\"ID\"]),list(styles_predicted[\"styles\"]),list(styles_predicted[\"ID\"])\n",
        "  # Sort both by ID\n",
        "  actual_outs = [x for _,x in sorted(zip(actual_ids,actual_outs))]\n",
        "  actual_ids = sorted(actual_ids)\n",
        "  pred_outs = [x for _,x in sorted(zip(pred_ids,pred_outs))]\n",
        "  del pred_ids\n",
        "  # Start scoring them all by similarity and constantly print the best one\n",
        "  best_score,bsi = np.inf,-1\n",
        "  for i in range(len(actual_outs)):\n",
        "    # Convert the pred_outs[i] string to a list\n",
        "    po = pred_outs[i]\n",
        "    po = po.split(\" \")\n",
        "    for j in range(len(po)):\n",
        "      po[j] = po[j].replace(\"[\",\"\")\n",
        "      po[j] = po[j].replace(\"]\",\"\")\n",
        "    j = 0\n",
        "    while(j<len(po)):\n",
        "      if(type(po[j])==float):\n",
        "        continue\n",
        "      if(len(po[j])==0):\n",
        "        po.pop(j)\n",
        "        continue\n",
        "      try:\n",
        "        po[j] = float(po[j])\n",
        "        j += 1\n",
        "      except:\n",
        "        po.pop(i)\n",
        "    res = compare_to_styles(style_tens[0],actual_outs[i],po,pred_weight = prediction_weightings)\n",
        "    # If the new result is more similar than the current best, report this, and update the best score + best score index\n",
        "    if(res<=best_score):\n",
        "      print(f\"Current best clothing found: ID {actual_ids[i]} with similarity of {res}\")\n",
        "      best_score = res\n",
        "      bsi = i\n",
        "  return actual_ids[bsi]\n",
        "\n",
        "# Compare an image output to known clothing styles and style predictions\n",
        "def compare_to_styles(image_style_preds,true_styles,predicted_styles=False,pred_weight = 0.5):\n",
        "  sim = 0.0\n",
        "  for i in range(len(image_style_preds)):\n",
        "    sim += abs(image_style_preds[i]-float(true_styles[i]))\n",
        "    # If the predictions of this clothing image is known, add the differences here. If not, add the 'pred_weight'\n",
        "    if(type(predicted_styles)!=bool):\n",
        "      sim += pred_weight * abs(image_style_preds[i]-float(predicted_styles[i]))\n",
        "    else:\n",
        "      sim += pred_weight\n",
        "  return sim\n",
        "\n",
        "# Get prediction for emotion types\n",
        "def predict_emotion(imgtens,predictor):\n",
        "  hipster_emote_preds = predictor.model.predict(imgtens)\n",
        "  return pd.DataFrame(data=hipster_emote_preds,columns=[\"prob_peaceful\",\"prob_happy\",\"prob_gloomy\",\"prob_scary\"])\n",
        "\n",
        "\n",
        "# Get predictions for media types\n",
        "def predict_media(imgtens,predictor):\n",
        "  hipster_media_preds = predictor.model.predict(imgtens)\n",
        "  return pd.DataFrame(data=hipster_media_preds,columns=[\"prob_pen\",\"prob_oilpaint\",\"prob_watercolor\",\"prob_comic\",\"prob_graphite\",\"prob_vectorart\",\"prob_3d\"])\n",
        "\n",
        "def predict_features(imgdirs,\n",
        "                     emote_predictor = Predictor(\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/BAM/models/2022-07-13/prototype-emotion-1\"),\n",
        "                     media_predictor = Predictor(\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/BAM/models/2022-07-13/prototype-media-1\"),\n",
        "                     emote_save_dir = False,\n",
        "                     media_save_dir = False):\n",
        "  # Convert the image directories to tensors\n",
        "  tens = dirs_to_tensors(imgdirs)\n",
        "  # Predict this list of tensors\n",
        "  emote_pred = predict_emotion(tens,emote_predictor)\n",
        "  media_pred = predict_media(tens,media_predictor)\n",
        "  # Delete the initial tensors\n",
        "  del tens\n",
        "  # Save the dataframe if appropriate\n",
        "  if(type(emote_save_dir)==str):\n",
        "    with open(emote_save_dir,\"w\") as f:\n",
        "      emote_pred.to_csv(f,index=False,line_terminator=\"\\n\")\n",
        "  if(type(media_save_dir)==str):\n",
        "    with open(media_save_dir,\"w\") as f:\n",
        "      media_pred.to_csv(f,index=False,line_terminator=\"\\n\")\n",
        "  # Convert the predictions to single 11-column tensors\n",
        "  tens = []\n",
        "  for ind in emote_pred.index:\n",
        "    tens.append(tf.convert_to_tensor(list(emote_pred.iloc[ind])+list(media_pred.iloc[ind])))\n",
        "  tens = tf.convert_to_tensor(tens)\n",
        "  return tens\n",
        "\n",
        "## Create a dataframe with feature outputs and clothing styles\n",
        "def get_hipsterdata(attribute_types = [\"emote\",\"media\"]):\n",
        "  # Get the image directories and CNN outputs\n",
        "  data = combine_preds(attribute_types)\n",
        "  # Add the image ids and styles\n",
        "  clothing_csv = pd.read_csv(open(\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/HipsterWars/hipster_to_csv_test.csv\",\"r\"))\n",
        "  labels = list(clothing_csv[\"Label\"])\n",
        "  # Convert the directories to ids\n",
        "  dirids = list(data[\"image_directory\"])\n",
        "  ids,nums = [],{}\n",
        "  for i in range(10):\n",
        "    nums[str(i)] = True\n",
        "  for dirid in dirids:\n",
        "    # Get the first number in the string\n",
        "    numdec = len(dirid)-5\n",
        "    while(dirid[numdec-1] in nums):\n",
        "      numdec -= 1\n",
        "    # Append the id only\n",
        "    ids.append(int(dirid[numdec:-4]))\n",
        "  # Add the IDs to the original data\n",
        "  data[\"ID\"] = ids\n",
        "  del data[\"image_directory\"]\n",
        "  # Get the styles for each value\n",
        "  styles = []\n",
        "  styledict = {\"Hipster\":0,\"Goth\":1,\"Preppy\":2,\"Pinup\":3,\"Bohemian\":4}\n",
        "  for tempid in ids:\n",
        "    temp = clothing_csv.loc[clothing_csv[\"ID\"]==tempid]\n",
        "    label = list(temp[\"Label\"])[0]\n",
        "    labellist = [0 for i in range(len(styledict))]\n",
        "    labellist[styledict[label]] += 1\n",
        "    label = tf.convert_to_tensor(labellist,dtype=float)\n",
        "    styles.append(label)\n",
        "  data[\"style\"] = styles\n",
        "  return data\n",
        "\n",
        "## Take HipsterWars predictions and combine them into single tensors\n",
        "def combine_preds(types=[\"emote\",\"media\"]):\n",
        "  framelocs = {\"emote\":\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/HipsterWars/emotion_predictions.csv\",\"media\":\"/content/drive/MyDrive/Data-Science/Art-to-fashion/Data/HipsterWars/media_predictions.csv\"}\n",
        "  frames = []\n",
        "  for frameloc in types:\n",
        "    frames.append(pd.read_csv(framelocs[frameloc]))\n",
        "  imdirs = frames[0][\"image_directory\"]\n",
        "  outs = []\n",
        "  for frame in frames:\n",
        "    for col in frame.columns:\n",
        "      if(col==\"image_directory\"):\n",
        "        continue\n",
        "      outs.append(list(frame[col]))\n",
        "  # Invert the lists obtained\n",
        "  outputs = [list(i) for i in zip(*outs)]\n",
        "  del outs\n",
        "  # Convert the outputs to tensors\n",
        "  for i in range(len(outputs)):\n",
        "    outputs[i] = tf.convert_to_tensor(outputs[i],dtype=float)\n",
        "  # Convert to dataframe\n",
        "  return pd.DataFrame(data=list(zip(imdirs,outputs)),columns = [\"image_directory\",\"output\"])\n",
        "\n",
        "# Convert a series of image directories to tensors\n",
        "def dirs_to_tensors(dirlist):\n",
        "  imglist = [load_img(imdir) for imdir in dirlist]\n",
        "  tenlist = [tf.convert_to_tensor(x) for x in imglist]\n",
        "  del imglist\n",
        "  inten = tf.convert_to_tensor(tenlist)\n",
        "  del tenlist\n",
        "  return inten\n",
        "\n",
        "# Load image, taken from BAM attributions.py\n",
        "def load_img(fdir,model_shape=(224,224)):\n",
        "  img = Image.open(tf.io.gfile.GFile(fdir, 'rb'))\n",
        "  img = preprocess_img(img,model_shape)\n",
        "  return img\n",
        "\n",
        "# Preprocessing single image; main part is resizing the image to 224x224x3\n",
        "def preprocess_img(img,model_shape=(224,224),_means=[123.68, 116.78, 103.94]):\n",
        "    img = img.convert('RGB').resize(model_shape, Image.BILINEAR)\n",
        "    channel_means = np.expand_dims(np.expand_dims(_means, 0), 0)\n",
        "    img_arr = np.array(img, dtype=np.float32) - channel_means.astype(np.float32)\n",
        "    return img_arr"
      ],
      "metadata": {
        "id": "EbZ1Kg2M4KDx"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}